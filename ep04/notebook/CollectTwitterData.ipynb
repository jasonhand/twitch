{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Tweets by Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies & Keys\n",
    "\n",
    "## Load Dependencies:\n",
    " - tweepy (python library to access Twitter API)\n",
    " - json (display results in json format)\n",
    " - numpy (saving large dimensional arrays)\n",
    " - pandas (data frames)\n",
    " - vaderSentiment (Sentiment Analysis)\n",
    "\n",
    "## Keys\n",
    " - Create a Twitter developer account and create an app to create custom keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/a3/1218a3b5651dbcba1699101c84e5c84c36cbba360d9dbf29f2ff18482982/vaderSentiment-3.3.1-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "## Keys\n",
    "consumer_key = \"xxxxx_change_me\"\n",
    "consumer_secret = \"xxxxx_change_me\"\n",
    "access_token = \"xxxxx_change_me\"\n",
    "access_token_secret = \"xxxxx_change_me\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gather tweets\n",
    "\n",
    "## Variable Inputs:\n",
    "\n",
    "### search_term\n",
    "-  Enter whatever custom search term you desire to search for...\n",
    "\n",
    "### oldest_tweet\n",
    "-  Enter in a tweet id for the most recent tweet id you want to search for, so all tweets gathered while executing will have a tweet id > oldest_tweet\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "## Cell Outputs:\n",
    "\n",
    "### Print the number of tweets collected.\n",
    "-  If you are not hitting any query limits, this code should collect 5,000 tweets.\n",
    "\n",
    "### Print the total number of items in the TempDict list.\n",
    "-  This value should match the total number of tweets collected (counter).\n",
    "\n",
    "### Print the total number of unique tweet ids'.\n",
    "-  This value should also match the total number of tweets and number of items in the TempDict list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were a total of 5000 tweets captured\n",
      "There are a total of 5000 objects in the dictionary\n",
      "There are a total of 5000 unique ids\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------\n",
    "# Execute Search\n",
    "#---------------------------------\n",
    "\n",
    "# Search for People Tweeting about Mark Hamill\n",
    "search_term = \"#EarthDay\"\n",
    "\n",
    "# Create variable for holding the oldest tweet\n",
    "oldest_tweet = 1252611119996420096\n",
    "\n",
    "# List to hold unique IDs\n",
    "unique_ids = []\n",
    "TempDict = []\n",
    "\n",
    "# Counter to keep track of the number of tweets retrieved\n",
    "counter = 0\n",
    "\n",
    "# Loop through 5 times (total of 5000 tweets)\n",
    "for x in range(50):\n",
    "\n",
    "    # Retrieve 100 most recent tweets -- specifying a max_id\n",
    "    public_tweets = api.search(search_term, \n",
    "                               count=100, \n",
    "                               result_type=\"recent\", \n",
    "                               max_id=oldest_tweet)\n",
    "\n",
    "    # Print Tweets\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        \n",
    "        if tweet_id not in unique_ids:\n",
    "            unique_ids.append(tweet_id)\n",
    "            TempDict.append(tweet)\n",
    "\n",
    "                        \n",
    "            # Increase counter by 1\n",
    "            counter += 1\n",
    "\n",
    "        # Reassign the the oldest tweet (i.e. the max_id)\n",
    "        # Subtract 1 so the previous oldest isn't included\n",
    "        # in the new search\n",
    "        oldest_tweet = tweet_id - 1\n",
    "print(f\"There were a total of {counter} tweets captured\")\n",
    "print(f\"There are a total of {len(TempDict)} objects in the dictionary\")\n",
    "print(f\"There are a total of {len(unique_ids)} unique ids\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique IDs:            5000\n",
      "Number of ID's Pulled in Run:    5000\n",
      "The current oldest tweet is:     1252585562344546303\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Verify Run\n",
    "########################\n",
    "\n",
    "# Number of Unique ID's Collected\n",
    "len(unique_ids)\n",
    "print(f\"Number of Unique IDs:            {len(unique_ids)}\")\n",
    "\n",
    "# Number of ID's Pulled in latest run\n",
    "print(f\"Number of ID's Pulled in Run:    {len(TempDict)}\")\n",
    "\n",
    "# Oldest Tweet Number\n",
    "print(f\"The current oldest tweet is:     {oldest_tweet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Save Results\n",
    "\n",
    "### Save json file\n",
    "-  enter json file name in line 7 (\"filename.json\")\n",
    "\n",
    "### Save csv file\n",
    "-  enter csv file name in line 6 ('filename.csv')\n",
    "\n",
    "### Save id numbers\n",
    "-  enter npy file name ('filename.npy')\n",
    "\n",
    "### Print a single full tweet response\n",
    "-  You can change the integer in FirstEntries[0] to any number between 0 and the one number less than the number of tweets collected.\n",
    "- i.e., if 5,000 tweets were collected, you can change the 0 to any number between 0 - 4999, or pick a range of numbers (0:5). Each tweet response is very large, so you probably only want to print a single tweet response just to verify what has been collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The json file was saved successfully\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "### Save TempDict as JSON File\n",
    "#########################\n",
    "\n",
    "import json\n",
    "json978 = json.dumps(TempDict)\n",
    "f = open(\"EarthDay.json\", \"w\")\n",
    "f.write(json978)\n",
    "f.close\n",
    "print(\"The json file was saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The json file was successfully saved as a CSV\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "### Create CSV File of DataFrame\n",
    "#########################\n",
    "\n",
    "TempDF = pd.DataFrame.from_dict(TempDict)\n",
    "TempDF.to_csv('EarthDay.csv')\n",
    "print(\"The json file was successfully saved as a CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Saving Unique ID Numbers to Numpy File\n",
    "#########################\n",
    "\n",
    "# unique_ids.tofile('EarthDay_UniqueIds.dat')\n",
    "\n",
    "np.save('EarthDay_UniqueIDs.npy', unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Tue Apr 21 14:52:18 +0000 2020',\n",
       " 'id': 1252611119996420096,\n",
       " 'id_str': '1252611119996420096',\n",
       " 'text': 'The advice her mother gave her at 10 years old, is the same advice Jane Goodall shares with young people today… https://t.co/VVKPvNzX93',\n",
       " 'truncated': True,\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': [{'url': 'https://t.co/VVKPvNzX93',\n",
       "    'expanded_url': 'https://twitter.com/i/web/status/1252611119996420096',\n",
       "    'display_url': 'twitter.com/i/web/status/1…',\n",
       "    'indices': [112, 135]}]},\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'source': '<a href=\"https://studio.twitter.com\" rel=\"nofollow\">Twitter Media Studio</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 17471979,\n",
       "  'id_str': '17471979',\n",
       "  'name': 'National Geographic',\n",
       "  'screen_name': 'NatGeo',\n",
       "  'location': 'Global',\n",
       "  'description': 'Taking our understanding and awareness of the world further for more than 130 years',\n",
       "  'url': 'http://t.co/mwaSar7U14',\n",
       "  'entities': {'url': {'urls': [{'url': 'http://t.co/mwaSar7U14',\n",
       "      'expanded_url': 'http://www.nationalgeographic.com/',\n",
       "      'display_url': 'nationalgeographic.com',\n",
       "      'indices': [0, 22]}]},\n",
       "   'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 23897907,\n",
       "  'friends_count': 81,\n",
       "  'listed_count': 65560,\n",
       "  'created_at': 'Tue Nov 18 21:28:10 +0000 2008',\n",
       "  'favourites_count': 6798,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'verified': True,\n",
       "  'statuses_count': 54525,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': True,\n",
       "  'profile_background_color': '292828',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1251261348689952768/PclReF5n_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1251261348689952768/PclReF5n_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/17471979/1587158929',\n",
       "  'profile_link_color': 'F5CE23',\n",
       "  'profile_sidebar_border_color': 'FFFFFF',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': False,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'regular'},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 1251,\n",
       " 'favorite_count': 4029,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "### Print First Full Tweet Response to Inspect\n",
    "#########################\n",
    "\n",
    "FirstEntries = TempDict[0:10]\n",
    "FirstEntries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#################################################################################\n",
    "####### NOT for running - this is notes and the legand\n",
    "#################################################################################\n",
    "\n",
    "#     tweet['created_at']                               # Time Stamp of when tweet was created\n",
    "#     tweet['id']                                       # tweet id Object (number)\n",
    "#     tweet['id_str']                                   # tweet id String format (number)\n",
    "#     tweet['text']                                     # text of tweet\n",
    "#     tweet['entities']['hashtags']['text']             # hashtags taken\n",
    "#     tweet['entities']['user_mentions']['screen_name'] # screen name of person mentioned\n",
    "#     tweet['entities']['user_mentions']['name']        # name of person mentioned\n",
    "#     tweet['user']['id']                               # id (object) of account user\n",
    "#     tweet['user']['name']                             # name of account user\n",
    "#     tweet['user']['screen_name']                      # Screen name of person\n",
    "#     tweet['user']['location']                         # string, user input of their location\n",
    "#     tweet['user']['description']                      # description of the account user\n",
    "#     tweet['user']['followers_count']                  # number of accounts user is following\n",
    "#     tweet['user']['friends_count']                    # number of accounts user is friends with\n",
    "#     tweet['user']['verified']                         # is the account user 'verified'\n",
    "#     tweet['geo']                                      # is geo null or on\n",
    "#     tweet['coordinates']                              # coordinates or null\n",
    "#     tweet['place']                                    # tweet place description or null\n",
    "#     tweet['retweeted_status']['id']                   # Original tweet id number object\n",
    "#     tweet['retweeted_status']['id_str']               # Original tweet id number string\n",
    "#     tweet['retweet_count']                            # number of times an original tweet has been retweeted\n",
    "#     tweet['retweeted_status']['favorite_count']       # number of times a tweet has been favorited"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
